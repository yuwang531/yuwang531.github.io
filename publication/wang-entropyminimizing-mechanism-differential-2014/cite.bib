@inproceedings{wang_EntropyminimizingMechanismDifferential_2014,
 abstract = {The concept of differential privacy stems from the study of private query of datasets. In this work, we apply this concept to metric spaces to study a mechanism that randomizes a deterministic query by adding mean-zero noise to keep differential privacy. For one-shot queries, we show that $覺n$-differential privacy of an n-dimensional input implies a lower bound n - n ln($覺n$/2) on the entropy of the randomized output, and this lower bound is achieved by adding Laplacian noise. We then consider the $覺n$-differential privacy of a discrete-time linear feedback system in which noise is added to the system output at each time. The adversary estimates the system states from the output history. We show that, to keep the system $覺n$-differentially private, the output entropy is bounded below, and this lower bound is achieves by an explicit mechanism.},
 author = {Wang, Yu and Huang, Zhenqi and Mitra, Sayan and Dullerud, Geir E.},
 booktitle = {53rd IEEE Conference on Decision and Control (CDC)},
 pages = {2130-2135},
 title = {Entropy-Minimizing Mechanism for Differential Privacy of Discrete-Time Linear Feedback Systems},
 year = {2014}
}

